<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>EAR: Environment variables</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../logo_small.png"/></td>
  <td id="projectalign">
   <div id="projectname">EAR<span id="projectnumber">&#160;5.0</span>
   </div>
   <div id="projectbrief">Reference Manual</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d7/d5f/md_EAR_environment_variables.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">Environment variables </div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#autotoc_md25">Introduction</a></li>
<li class="level1"><a href="#autotoc_md26">Loading EAR Library</a><ul><li class="level2"><a href="#ear_loader_application">EAR_LOADER_APPLICATION</a></li>
<li class="level2"><a href="#ear_load_mpi_version">EAR_LOAD_MPI_VERSION</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md27">Report plug-ins</a><ul><li class="level2"><a href="#ear-report-add">EAR_REPORT_ADD</a></li>
</ul>
</li>
<li class="level1"><a href="#verbosity">Verbosity</a><ul><li class="level2"><a href="#earl_verbose_path">EARL_VERBOSE_PATH</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md28">Frequency management</a><ul><li class="level2"><a href="#autotoc_md29">EAR_GPU_DEF_FREQ</a></li>
<li class="level2"><a href="#autotoc_md30">EAR_JOB_EXCLUSIVE_MODE</a></li>
<li class="level2"><a href="#controlling-uncore-infinity-fabric-frequency">Controlling Uncore/Infinity Fabric frequency</a><ul><li class="level3"><a href="#ear_set_imcfreq">EAR_SET_IMCFREQ</a></li>
<li class="level3"><a href="#ear_max_imcfreq-and-ear_min_imcfreq">EAR_MAX_IMCFREQ and EAR_MIN_IMCFREQ</a></li>
</ul>
</li>
<li class="level2"><a href="#load-balancing">Load Balancing</a><ul><li class="level3"><a href="#autotoc_md31">EAR_LOAD_BALANCE</a></li>
</ul>
</li>
<li class="level2"><a href="#support-for-intel-r-speed-select-technology">Support for Intel(R) Speed Select Technology</a><ul><li class="level3"><a href="#ear_prio_tasks">EAR_PRIO_TASKS</a></li>
<li class="level3"><a href="#ear_prio_cpus">EAR_PRIO_CPUS</a></li>
</ul>
</li>
<li class="level2"><a href="#autotoc_md32">EAR_MIN_CPUFREQ</a></li>
<li class="level2"><a href="#autotoc_md33">Disabling EAR&#39;s affinity masks usage</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md34">Workflow support</a><ul><li class="level2"><a href="#autotoc_md35">EAR_DISABLE_NODE_METRICS</a></li>
<li class="level2"><a href="#autotoc_md36">EAR_NTASK_WORK_SHARING</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md37">Data gathering/reporting</a><ul><li class="level2"><a href="#autotoc_md38">EARL_REPORT_LOOPS</a></li>
<li class="level2"><a href="#ear_get_mpi_stats">EAR_GET_MPI_STATS</a></li>
<li class="level2"><a href="#ear_trace_plugin">EAR_TRACE_PLUGIN</a></li>
<li class="level2"><a href="#autotoc_md39">EAR_TRACE_PATH</a></li>
<li class="level2"><a href="#report_earl_events">REPORT_EARL_EVENTS</a><ul><li class="level3"><a href="#autotoc_md40">Event types</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="autotoc_md25"></a>
Introduction</h1>
<p>EAR offers some environment variables in order to provide users the opportunity to tune or request some of EAR features. They must be exported before the job submission, e.g., in the batch script.</p>
<p>The current EAR version has support for <a href="https://slurm.schedmd.com/">SLURM</a>, <a href="https://www.altair.com/pbs-professional/">PBS</a> and <a href="https://oar.imag.fr/start">OAR</a> batch schedulers. In SLURM systems the scheduler may filter environment variables not prefixed with <em>SLURM_</em> character set (this happens when the batch script is submitted purging all environment variables to work in a clean environment). For that reason, the first design of EAR environment variables was to have variable names with the form <em>SLURM_</em>&lt;variable_name&gt;.</p>
<p>Now that EAR has support for other batch schedulers, and in order to maintain the coherency of environment variables names, below environment variables need the prefix of the scheduler used on the system the job is submitted on, plus an underscore. For example, in SLURM systems, the environment variable presented as <code>EAR_LOADER_APPLICATION</code> must be exported as <code>SLURM_EAR_LOADER_APPLICATION</code> in the submission batch script. In an OAR installed system, this variable would be exported as <code>OAR_EAR_LOADER_APPLICATION</code>. This design may only have a real effect on SLURM systems, but it makes it easier for the development team to provide support for multiple batch schedulers.</p>
<p>All examples showing the usage of below environment variables assume a system using SLURM.</p>
<h1><a class="anchor" id="autotoc_md26"></a>
Loading EAR Library</h1>
<h2><a class="anchor" id="ear_loader_application"></a>
EAR_LOADER_APPLICATION</h2>
<p>Rules the EAR Loader to load the EAR Library for a specific application that does not follow any of the current programming models (or maybe a sequential app) supported by EAR. Your system must have installed the non-MPI version of the Library (ask your system administrator).</p>
<p>The value of the environment variable must coincide with the job name of the application you want to launch with EAR. If you don’t provide it, the EAR Loader will compare it against the executable name. For example:</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line"> </div>
<div class="line">export EAR_LOADER_APPLICATION=my_job_name</div>
<div class="line"> </div>
<div class="line">srun --ntasks 1 --job-name=my_job_name ./my_exec_file</div>
</div><!-- fragment --><p>See the <a class="el" href="../../d6/d86/md_User_guide.html#use-cases">Use cases</a> section to read more information about how to run jobs with EAR.</p>
<h2><a class="anchor" id="ear_load_mpi_version"></a>
EAR_LOAD_MPI_VERSION</h2>
<p>Forces to load a specific MPI version of the EAR Library. This is needed, for example, when you want to load the EAR Library for Python + MPI applications, where the Loader is not able to detect the MPI implementation the application is going to use. Accepted values are either <em>intel</em> or <em>open mpi</em>. The following example runs Tensorflow 1 benchmarks for several convulational neural networks with EAR. It can be downloaded from Tensorflow benchmarks <a href="https://github.com/tensorflow/benchmarks">repository</a>.</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line"> </div>
<div class="line">#SBATCH --job-name=TensorFlow</div>
<div class="line">#SBATCH -N 8</div>
<div class="line">#SBATCH --ntasks-per-node=4</div>
<div class="line">#SBATCH --cpus-per-task=18</div>
<div class="line"> </div>
<div class="line"># Specific modules here</div>
<div class="line"># ...</div>
<div class="line"> </div>
<div class="line">export EAR_LOAD_MPI_VERSION=&quot;open mpi&quot;</div>
<div class="line"> </div>
<div class="line">srun --ear-policy=min_time \</div>
<div class="line">    python benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \</div>
<div class="line">    ... more application options</div>
</div><!-- fragment --><p>See the <a class="el" href="../../d6/d86/md_User_guide.html#use-cases">Use cases</a> section to read more information about how to run jobs with EAR.</p>
<h1><a class="anchor" id="autotoc_md27"></a>
Report plug-ins</h1>
<h2><a class="anchor" id="ear-report-add"></a>
EAR_REPORT_ADD</h2>
<p>Specify a report plug-in to be loaded. The value must be a shared object file, and it must be located at <code>$EAR_INSTALL_PATH/lib/plugins/report</code> or at the path from where the job was launched. Alternatively, you can provide the full path (absolute or relative) of the report plug-in.</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line"> </div>
<div class="line">export EAR_REPORT_ADD=my_report_plugin.so:my_report_plugin2.so</div>
<div class="line"> </div>
<div class="line">srun -n 10 my_mpi_app</div>
</div><!-- fragment --><h1><a class="anchor" id="verbosity"></a>
Verbosity</h1>
<h2><a class="anchor" id="earl_verbose_path"></a>
EARL_VERBOSE_PATH</h2>
<p>Specify a path to create a file (one per node involved in a job) where to print messages from the EAR Library. This is useful when you run a job in multiple nodes, as EAR verbose information for each of them can result in lots of messages mixed at stderr (EAR messages default channel). Also, there are applications that print information in both stdout and stderr, so maybe a user wants to have information separated.</p>
<p>If the path does not exist, EAR will create it. The format of generated files names is <code>earl_log.&lt;node_rank&gt;.&lt;local_rank&gt;.&lt;job_step&gt;.&lt;job_id&gt;</code>, where the <em>node_rank</em> is an integer set by EAR from 0 to <em>n_nodes - 1</em> involved in the job, and it indicates to which node the information belongs to. The local rank is an arbitrary rank set by EAR of a process in the node (from 0 to <em>n_procceses_in_node - 1</em>). It indicates which process is printing messages to the files, and it will be always the first one indexed, i.e., 0. Finally, the <em>job_step</em> and <em>job_id</em> are fields showing information about the job corresponding to the execution from where messages were generated.</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line"> </div>
<div class="line">#SBATCH -j my_job_name</div>
<div class="line">#SBATCH -N 2</div>
<div class="line">#SBATCH -n 96</div>
<div class="line"> </div>
<div class="line">export EARL_VERBOSE_PATH=ear_logs_dir_name</div>
<div class="line">export I_MPI_HYDRA_BOOTSTRAP=slurm</div>
<div class="line">export I_MPI_HYDRA_BOOTSTRAP_EXEC_EXTRA_ARGS=”--ear-verbose=1”</div>
<div class="line"> </div>
<div class="line">mpirun -np 96 -ppn 48 my_app</div>
</div><!-- fragment --><p>After the above job example completion, in the same directory where the application was submitted, there will be a directory called <em>ear_logs_dir_name</em> with two files, i.e., one for each node, called <em>earl_logs.0.0.&lt;job_step&gt;.&lt;job_id&gt;</em> and <em>earl_logs.1.0.&lt;job_step&gt;.&lt;job_id&gt;</em>, respectively.</p>
<h1><a class="anchor" id="autotoc_md28"></a>
Frequency management</h1>
<h2><a class="anchor" id="autotoc_md29"></a>
EAR_GPU_DEF_FREQ</h2>
<p>Set a GPU frequency (in kHz) to be fixed while your job is running. The same frequency is set for all GPUs used by the job.</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line"> </div>
<div class="line">#SBATCH -J gromacs-cuda</div>
<div class="line">#SBATCH -N 1</div>
<div class="line"> </div>
<div class="line">export I_MPI_PIN=1</div>
<div class="line">export I_MPI_PMI_LIBRARY=/usr/lib64/libpmi2.so</div>
<div class="line"> </div>
<div class="line">input_path=/hpc/appl/biology/GROMACS/examples</div>
<div class="line">input_file=ion_channel.tpr</div>
<div class="line">GROMACS_INPUT=$input_path/$input_file</div>
<div class="line"> </div>
<div class="line">export EAR_GPU_DEF_FREQ=1440000</div>
<div class="line"> </div>
<div class="line">srun --cpu-bind=core --ear-policy=min_energy gmx_mpi mdrun \</div>
<div class="line">    -s $GROMACS_INPUT -noconfout -ntomp 1</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md30"></a>
EAR_JOB_EXCLUSIVE_MODE</h2>
<p>Indicate whether the job will run in a node exclusively (non-zero value). EAR will reduce the CPU frequency of those cores not used by the job. This feature explodes a very easy vector of power saving.</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line">#SBATCH -N 1</div>
<div class="line">#SBATCH -n 64</div>
<div class="line">#SBATCH --cpus-per-task=2</div>
<div class="line">#SBATCH --exclusive</div>
<div class="line"> </div>
<div class="line">export EAR_JOB_EXCLUSIVE_MODE=1</div>
<div class="line"> </div>
<div class="line">srun -n 10 --ear=on ./mpi_mpi_app</div>
</div><!-- fragment --><h2><a class="anchor" id="controlling-uncore-infinity-fabric-frequency"></a>
Controlling Uncore/Infinity Fabric frequency</h2>
<p>EARL offers the possibility to control the Integrated Memory Controller (IMC) for Intel(R) architectures and Infinity Fabric (IF) for AMD architectures. On this page we will use the term <em>uncore</em> to refer both of them. Environment variables related to uncore control covers <a class="el" href="../../d7/d5f/md_EAR_environment_variables.html#ear_set_imcfreq">policy specific settings</a> or the chance for a user to <a class="el" href="../../d7/d5f/md_EAR_environment_variables.html#ear_max_imcfreq-and-ear_min_imcfreq">fix it</a> during an entire job.</p>
<h3><a class="anchor" id="ear_set_imcfreq"></a>
EAR_SET_IMCFREQ</h3>
<p>Enables/disables EAR's [eUFS](publications) feature. Type <code>ear-info</code> to see whehter eUFS is enabled by default.</p>
<p>You can control eUFS' maximum permitted time penalty by exporting <code>EAR_POLICY_IMC_TH</code>, which is a float indicating the threshold value that prevents the policy to reduce so much the uncore frequency, possible leading to considerable performance penalty.</p>
<p>Below example enables eUFS with a penalty threshold of 3.5%:</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">export SLURM_EAR_SET_IMCFREQ=1</div>
<div class="line">export SLURM_EAR_POLICY_IMC_TH=0.035</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">srun [...] my_app</div>
</div><!-- fragment --><h3><a class="anchor" id="ear_max_imcfreq-and-ear_min_imcfreq"></a>
EAR_MAX_IMCFREQ and EAR_MIN_IMCFREQ</h3>
<p>Set the maximum and minimum values (in kHz) at which <em>uncore</em> frequency should be. Two variables were designed because Intel(R) architectures let to set a range of frequencies that limits its internal UFS mechanism. If you set both variables with different values, the minimum one will be set.</p>
<p>Below example shows a job execution fixing the uncore frequency at 2.0GHz:</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">export EAR_MAX_IMCFREQ=2000000</div>
<div class="line">export EAR_MIN_IMCFREQ=2000000</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">srun [...] my_app</div>
</div><!-- fragment --><h2><a class="anchor" id="load-balancing"></a>
Load Balancing</h2>
<p>By default, EAR policies try to set the best CPU (and uncore, if <a class="el" href="../../d7/d5f/md_EAR_environment_variables.html#controlling-uncore-infinity-fabric-frequency">enabled</a>) frequency according to node grain metrics. This behaviour can be changed telling EAR to detect and deal with unbalanced workloads, i.e., there is no equity between processes regarding their MPI/computational activity.</p>
<p>When EAR detects such behaviour, policies slightly modify its way of CPU frequency selection by setting a different frequency for each process' cores according how far it is from the critical path. Please, contact with <a href="#" onclick="location.href='mai'+'lto:'+'ear'+'-s'+'upp'+'or'+'t@b'+'sc'+'.es'; return false;">ear-support@bsc.es</a> if you want more details about how it works.</p>
<blockquote class="doxtable">
<p>&zwj;A correct CPU binding it's required to get the most benefit of this feature. Check the documentation of you application programming model/vendor/flavour or yur system batch scheduler. </p>
</blockquote>
<h3><a class="anchor" id="autotoc_md31"></a>
EAR_LOAD_BALANCE</h3>
<p>Enables/Disables EAR's Load Balance strategy in energy policies. Type <code>ear-info</code> to see whether this feature is enabled by default.</p>
<p>Load unbalance detection algorithm is based on <a href="https://pop-coe.eu/node/69">POP-CoE</a>'s Load Balance Efficiency metric, which is computed as the ratio between average useful computation time (across all processes) and maximum useful computation time (also across all processes). By default (if <code>EAR_LOAD_BALANCE</code> is enabled), a node load balance efficiency below <b>0.8</b> will trigger EAR's Load Balancing algorithm. This threshold value can be modified by setting <code>EAR_LOAD_BALANCE_TH</code> environment variable. For example, if you want to be more permissive with the application load balance and prevent per-process CPU frequency selection, you can increase the load balance threshold:</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">export EAR_LOAD_BALANCE=1</div>
<div class="line">export EAR_LOAD_BALANCE_TH=0.89</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">srun [...] my_app</div>
</div><!-- fragment --><h2><a class="anchor" id="support-for-intel-r-speed-select-technology"></a>
Support for Intel(R) Speed Select Technology</h2>
<p>Since version 4.2, EAR supports the interaction with <a href="https://www.intel.com/content/www/us/en/architecture-and-technology/speed-select-technology-article.html">Intel(R) Speed Select Technology (Intel(R) SST)</a> which lets the user to have more fine grained control over per-CPU Turbo frequency. This feature opens a door to users for getting more control over the performance (also power consumption) across CPUs running their applications and jobs. It is available on selected SKUs of Intel(R) Xeon(R) Scalable processors. For more information about Intel(R) SST, below are listed useful links to official documentation:</p>
<ul>
<li><a href="https://networkbuilders.intel.com/solutionslibrary/intel-speed-select-technology-core-power-intel-sst-cp-overview-technology-guide">Intel(R) SST-CP</a></li>
<li><a href="https://networkbuilders.intel.com/solutionslibrary/intel-speed-select-technology-turbo-frequency-intel-sst-tf-overview-user-guide">Intel(R) SST-TF</a></li>
<li><a href="https://docs.kernel.org/admin-guide/pm/intel-speed-select.html">The Linux Kernel: Intel(R) Speed Select Technology User Guide</a></li>
</ul>
<p>EAR offers two environment variables that let to specify a list of priorities (CLOS) in two different ways. The <a class="el" href="../../d7/d5f/md_EAR_environment_variables.html#ear_prio_tasks">first one</a> will set a CLOS for each task involved in the job. On the other hand, the <a class="el" href="../../d7/d5f/md_EAR_environment_variables.html#ear_prio_cpus">second offered variable</a> will set a list of priorities per CPU involved in the job. Values must be within the range of available CLOS that Intel(R) SST provides you.</p>
<p>If some of the two supported environment variables are set, EAR will set-up all of its internals transparently if the architecture supports it. Also, it will restore configuration on the job ending. If Intel(R) SST is not supported, no effect will occur. If you enable <a class="el" href="../../d6/d86/md_User_guide.html#ear-job-submission-flags">EARL verbosity</a> you will see the mapping of the CLOS set for each CPU in the node. Note that a <code>-1</code> value means that no change was done on the specific CPU.</p>
<h3><a class="anchor" id="ear_prio_tasks"></a>
EAR_PRIO_TASKS</h3>
<p>A list that specifies the CLOS that CPUs assigned to tasks must be set. This variable is useful because you can configure your application transparently without concerning about the affinity mask that the scheduler is assigning to your tasks. You can use this variable when you know (or guess) your application's tasks workload and you want to tune it by setting manually different Turbo priorities. Note that you still need to ensure that different tasks do not share CPUs.</p>
<p>For example, imagine you want to submit a job that runs a MPI application with 16 tasks, each one pinned on a single core, in a two-socket Intel(R) Xeon(R) Platinum 8352Y with 32 cores each, with Hyper-threading enabled, i.e., each task will run on two CPUs and 32 of the total 128 will be allocated by this application. Below could be a (simplified) batch script that submits this example:</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line"> </div>
<div class="line">export EAR_PRIO_TASKS=0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3</div>
<div class="line"> </div>
<div class="line">srun --ntasks=16 --cpu-bind=core,verbose --ear-policy=monitoring --ear-cpufreq=2201000 --ear-verbose=1 bin/bt.C.x</div>
</div><!-- fragment --><p>The above script sets CLOS 0 to tasks 0 to 3, CLOS 1 to tasks 4 to 7, CLOS 2 to tasks 8 to 11 and CLOS 3 to tasks 12 to 15. The <code>srun</code> command binds each task to one core (through <code>--cpu-bind</code> flag), sets the turbo frequency and enables EAR verbosity. Below there is the output message shown by the batch scheduler (i.e., SLURM):</p>
<div class="fragment"><div class="line">cpu-bind=MASK - ice2745, task  0  0 [23363]: mask 0x10000000000000001 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  1  1 [23364]: mask 0x1000000000000000100000000 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  2  2 [23365]: mask 0x20000000000000002 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  3  3 [23366]: mask 0x2000000000000000200000000 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  4  4 [23367]: mask 0x40000000000000004 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  5  5 [23368]: mask 0x4000000000000000400000000 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  6  6 [23369]: mask 0x80000000000000008 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  7  7 [23370]: mask 0x8000000000000000800000000 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  8  8 [23371]: mask 0x100000000000000010 set</div>
<div class="line">cpu-bind=MASK - ice2745, task  9  9 [23372]: mask 0x10000000000000001000000000 set</div>
<div class="line">cpu-bind=MASK - ice2745, task 10 10 [23373]: mask 0x200000000000000020 set</div>
<div class="line">cpu-bind=MASK - ice2745, task 11 11 [23374]: mask 0x20000000000000002000000000 set</div>
<div class="line">cpu-bind=MASK - ice2745, task 12 12 [23375]: mask 0x400000000000000040 set</div>
<div class="line">cpu-bind=MASK - ice2745, task 13 13 [23376]: mask 0x40000000000000004000000000 set</div>
<div class="line">cpu-bind=MASK - ice2745, task 14 14 [23377]: mask 0x800000000000000080 set</div>
<div class="line">cpu-bind=MASK - ice2745, task 15 15 [23378]: mask 0x80000000000000008000000000 set</div>
</div><!-- fragment --><p>We can see here that SLURM spreaded out tasks accross the two sockets of the node, e.g., task 0 runs on CPUs 0 and 64, task 1 runs on CPUs 32 and 96. Below output shows how EAR sets and verboses CLOS list per CPU in the node. Following the same example, you can see that CPUs 0, 64, 32 and 96 have priority/CLOS 0. Note that those CPUs not involved in the job show a -1.</p>
<div class="fragment"><div class="line">Setting user-provided CPU priorities...</div>
<div class="line">PRIO0: MAX GHZ - 0.0 GHz (high)</div>
<div class="line">PRIO1: MAX GHZ - 0.0 GHz (high)</div>
<div class="line">PRIO2: MAX GHZ - 0.0 GHz (low)</div>
<div class="line">PRIO3: MAX GHZ - 0.0 GHz (low)</div>
<div class="line">[000, 0] [001, 0] [002, 1] [003, 1] [004, 2] [005, 2] [006, 3] [007, 3] </div>
<div class="line">[008,-1] [009,-1] [010,-1] [011,-1] [012,-1] [013,-1] [014,-1] [015,-1] </div>
<div class="line">[016,-1] [017,-1] [018,-1] [019,-1] [020,-1] [021,-1] [022,-1] [023,-1] </div>
<div class="line">[024,-1] [025,-1] [026,-1] [027,-1] [028,-1] [029,-1] [030,-1] [031,-1] </div>
<div class="line">[032, 0] [033, 0] [034, 1] [035, 1] [036, 2] [037, 2] [038, 3] [039, 3] </div>
<div class="line">[040,-1] [041,-1] [042,-1] [043,-1] [044,-1] [045,-1] [046,-1] [047,-1] </div>
<div class="line">[048,-1] [049,-1] [050,-1] [051,-1] [052,-1] [053,-1] [054,-1] [055,-1] </div>
<div class="line">[056,-1] [057,-1] [058,-1] [059,-1] [060,-1] [061,-1] [062,-1] [063,-1] </div>
<div class="line">[064, 0] [065, 0] [066, 1] [067, 1] [068, 2] [069, 2] [070, 3] [071, 3] </div>
<div class="line">[072,-1] [073,-1] [074,-1] [075,-1] [076,-1] [077,-1] [078,-1] [079,-1] </div>
<div class="line">[080,-1] [081,-1] [082,-1] [083,-1] [084,-1] [085,-1] [086,-1] [087,-1] </div>
<div class="line">[088,-1] [089,-1] [090,-1] [091,-1] [092,-1] [093,-1] [094,-1] [095,-1] </div>
<div class="line">[096, 0] [097, 0] [098, 1] [099, 1] [100, 2] [101, 2] [102, 3] [103, 3] </div>
<div class="line">[104,-1] [105,-1] [106,-1] [107,-1] [108,-1] [109,-1] [110,-1] [111,-1] </div>
<div class="line">[112,-1] [113,-1] [114,-1] [115,-1] [116,-1] [117,-1] [118,-1] [119,-1] </div>
<div class="line">[120,-1] [121,-1] [122,-1] [123,-1] [124,-1] [125,-1] [126,-1] [127,-1] </div>
</div><!-- fragment --><h3><a class="anchor" id="ear_prio_cpus"></a>
EAR_PRIO_CPUS</h3>
<p>A list of priorities that should have the same length as the number of CPUs your job is using. This configuration lets to set up CPUs CLOS in a more low level way: <b>the <em>n-th</em> priority value of the list will set the priority of the <em>n-th</em> CPU your job is using.</b></p>
<p>This way of configuring priorities rules the user to know exactly the affinity of its job's tasks before launching the application, so it becomes harder to use if your goal is the same as the one you can get by setting the <a class="el" href="../../d7/d5f/md_EAR_environment_variables.html#ear_prio_tasks">above environment variable</a>: task-focused CLOS setting. But it becomes more flexible when the user has more control over the affinity set to its application, because you can discriminate between different CPUs assigned to the same task. Moreover, this is the only way to set different priorities over different threads in no-MPI applications.</p>
<h2><a class="anchor" id="autotoc_md32"></a>
EAR_MIN_CPUFREQ</h2>
<p>This variable can only be set by <b>authorized users</b>, and modifies the minimum CPU frequency the EAR Library can set. The <a class="el" href="../../d2/d00/md_Configuration.html">EAR configuration</a> file has a field called <code>cpu_max_pstate</code> which sets this limits on the tag it is configured. Authorized users can modify this limit at submission time by using this environment to test, for example, the best value for the <code>ear.conf</code> field.</p>
<h2><a class="anchor" id="autotoc_md33"></a>
Disabling EAR's affinity masks usage</h2>
<p>For both [Load Balancing](load-balancing) and <a class="el" href="../../d7/d5f/md_EAR_environment_variables.html#support-for-intel-r-speed-select-technology">Intel(R) SST</a> support, EAR uses processes' affinity mask read at the beginning of the job. If you are working on an application that changes (or may change) the affinty mask of tasks dynamically, this can lead some miss configuration not detected by EAR. To avoid any unexpected problem, <b>we highly recommend you</b> to export <code>EARL_NO_AFFINITY_MASK</code> environment variable <b>even you are not planning to work with some of the mentioned features</b>.</p>
<p>Note: Since EAR version 5.0, EAR updates the process mask periodically (aprox 1 sec.) and always before applying the optimization policy.</p>
<h1><a class="anchor" id="autotoc_md34"></a>
Workflow support</h1>
<h2><a class="anchor" id="autotoc_md35"></a>
EAR_DISABLE_NODE_METRICS</h2>
<p>By defining this environment variable, the user or workflow manager indicates EAR the current process must not be considered as power consumer, not affecting the CPU power models used to estimate the amount of power corresponding to each application sharing a node. This env variable target master-worker scenarios (or map-reduce) when one process is not doing computational work, just working as master creating and waiting for processes. By specifying this var, the EARL ignores the affinity mas for this process and assumes its activity is not relevant for the whole power consumption. The value is not relevant, it only has to be defined. In a fork-join program (or similar, it has to be unset before the creation of the workers.</p>
<h2><a class="anchor" id="autotoc_md36"></a>
EAR_NTASK_WORK_SHARING</h2>
<p>By defining this environment variable, the user indicates the library the set of processes sharing the node are in fact a single application (not MPI). This enables a synchronization at the beginning and all the processes with same jobid and stepid (or similar for other schedulers different than SLURM) works together. Only one of the will be selected as the master and will apply the energy policy. For GPU applications it's mandatory the process can access all the GPUs. Otherwise, it is not recommended and each process will apply its own optimization. The value is not relevant, it only has to be defined. <b>This feature is only supported on systems using SLURM</b>.</p>
<h1><a class="anchor" id="autotoc_md37"></a>
Data gathering/reporting</h1>
<h2><a class="anchor" id="autotoc_md38"></a>
EARL_REPORT_LOOPS</h2>
<p>Since <b>version 4.3</b>, EAR can be configured to not report application loop signatures by default. This configuration satisfy a constraint for many HPC data centers where hundreds of jobs are launched daily, leading to too many loops reported and a quick EAR database size increase.</p>
<p>For those users which still want to get application loop data, this variable can be set to one (i.e., <code>export EARL_REPORT_LOOPS=1</code>) to force EAR report their application loop signatures. Therefore, users can get their loop data by calling <a class="el" href="../../dc/d09/md_EAR_commands.html#eacct">`eacct -j &lt;job_id&gt; -r`</a>.</p>
<h2><a class="anchor" id="ear_get_mpi_stats"></a>
EAR_GET_MPI_STATS</h2>
<p>Use this variable to generate two files at the end of the job execution that will contain global, per process MPI information. You must specify the prefix (optionally with a path) of the filename. One file (<em>[path/]prefix.ear_mpi_stats.full_nodename.csv</em>) will contain a resume about MPI throughput (per-process), while the other one (<em>[path/]prefix.ear_mpi_calls_stats.full_nodename.csv</em>) will contain a more fine grained information about different MPI call types. Here is an example:</p>
<div class="fragment"><div class="line">!#/bin/bash</div>
<div class="line"> </div>
<div class="line">#SBATCH -j mpi_job_name</div>
<div class="line">#SBATCH -n 48</div>
<div class="line"> </div>
<div class="line">MPI_INFO_DST=$SLURM_JOBID-mpi_stats</div>
<div class="line">mkdir $MPI_INFO_DST</div>
<div class="line"> </div>
<div class="line">export EAR_GET_MPI_STATS=$MPI_INFO_DST/$SLURM_JOB_NAME</div>
<div class="line"> </div>
<div class="line">srun -n 48 --ear=on ./mpi_app</div>
</div><!-- fragment --><p>At the end of the job, two files will be created at the directory named <code>\&lt;job_id\&gt;-mpi_stats</code> located in the same directory where the application was submitted. They will be named <em>mpi_job_name.ear_mpi_stats.full_nodename.csv</em> and <em>mpi_job_name.ear_mpi_calls_stats.full_nodename.csv</em>. File pairs will be created for each node involved in the job.</p>
<p>Take into account that each process appends its own MPI statistics to files. This behavior does not guarantee that the header of files will be on the first line of them, as only one process writes it. You must move it at the top of each file manually before reading them with some tool you use to visualize and work with CSV files, e.g., spreadsheet, a R or Python package.</p>
<p>Below table shows fields available by <b>ear_mpi_stats</b> file:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Field   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">mrank   </td><td class="markdownTableBodyNone">The EAR's internal node ID used to identify the node.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">lrank   </td><td class="markdownTableBodyNone">The EAR's internal rank ID used to identify the process.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">total_mpi_calls   </td><td class="markdownTableBodyNone">The total number of MPI calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">exec_time   </td><td class="markdownTableBodyNone">The execution time, in microseconds.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">mpi_time   </td><td class="markdownTableBodyNone">The time spent in MPI calls, in microseconds.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">perc_mpi_time   </td><td class="markdownTableBodyNone">The percentage of total execution time (i.e., <em>exec_time</em>) spent in MPI calls.   </td></tr>
</table>
<p>Below table shows fields available by <b>ear_mpi_calls_stats</b> file:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Field   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Master   </td><td class="markdownTableBodyNone">The EAR's internal node ID used to identify the node.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Rank   </td><td class="markdownTableBodyNone">The EAR's internal rank ID used to identify the process.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Total MPI calls   </td><td class="markdownTableBodyNone">The total number of MPI calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">MPI_time/Exec_time   </td><td class="markdownTableBodyNone">The ration between time spent in MPI calls and the total execution time.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Exec_time   </td><td class="markdownTableBodyNone">The execution time, in microseconds.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Sync_time   </td><td class="markdownTableBodyNone">Time spent (in microseconds) in <b>blocking</b> synchronization calls, i.e., MPI_Wait, MPI_Waitall, MPI_Waitany, MPI_Waitsome and MPI_Barrier.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Block_time   </td><td class="markdownTableBodyNone">Time spent in blocking calls, i.e., MPI_Allgather, MPI_Allgatherv, MPI_Allreduce, MPI_Alltoall, MPI_Alltoallv, MPI_Barrier, MPI_Bcast, MPI_Bsend, MPI_Cart_create, MPI_Gather, MPI_Gatherv, MPI_Recv, MPI_Reduce, MPI_Reduce_scatter, MPI_Rsend, MPI_Scan, MPI_Scatter, MPI_Scatterv, MPI_Send, MPI_Sendrecv, MPI_Sendrecv_replace, MPI_Ssend and all <em>Wait</em> calls of <b>Sync_time</b> field.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Collec_time   </td><td class="markdownTableBodyNone">Time spent in <b>blocking</b> collective calls, i.e., MPI_Allreduce, MPI_Reduce and MPI_Reduce_scatter.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Total MPI sync calls   </td><td class="markdownTableBodyNone">Total number of synchronization calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Total blocking calls   </td><td class="markdownTableBodyNone">Total number of blocking calls.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Total collective calls   </td><td class="markdownTableBodyNone">Total number of collective calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Gather   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Gather calls, i.e., MPI_Allgather, MPI_Allgatherv, MPI_Gather and MPI_Gatherv.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Reduce   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Reduce calls, i.e., MPI_Allreduce, MPI_Reduce and MPI_Reduce_scatter.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">All2all   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> All2all calls, i.e., MPI_Alltoall and MPI_Alltoallv.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Barrier   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Barrier calls, i.e., MPI_Barrier.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Bcast   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Bcast calls, i.e., MPI_Bcast.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Send   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Send calls, i.e., MPI_Bsend, MPI_Rsend, MPI_Send and MPI_Ssend.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Comm   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Comm calls, i.e., MPI_Cart_create.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Receive   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Receive calls, i.e., MPI_Recv.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Scan   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Scan calls, i.e., MPI_Scan.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Scatter   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Scatter calls, i.e., MPI_Scatter and MPI_Scatterv.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">SendRecv   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> SendRecv calls, i.e., MPI_Sendrecv, MPI_Sendrecv_replace.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Wait   </td><td class="markdownTableBodyNone">Total number of <b>blocking</b> Wait calls, i.e., all MPI_Wait calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">t_Gather   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Gather calls.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">t_Reduce   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Reduce calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">t_All2all   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> All2all calls.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">t_Barrier   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Barrier calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">t_Bcast   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Bcast calls.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">t_Send   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Send calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">t_Comm   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Comm calls.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">t_Receive   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Receive calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">t_Scan   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Scan calls.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">t_Scatter   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Scatter calls.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">t_SendRecv   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> SendRecv calls.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">t_Wait   </td><td class="markdownTableBodyNone">Time (in microseconds) spent in <b>blocking</b> Wait calls.   </td></tr>
</table>
<h2><a class="anchor" id="ear_trace_plugin"></a>
EAR_TRACE_PLUGIN</h2>
<p>EAR offers the chance to generate Paraver traces to visualize runtime metrics with the <a href="https://tools.bsc.es/paraver">Paraver tool</a>. Paraver is a visualization tool developed by CEPBA-Tools team and currently maintained by the Barcelona Supercomputing Center’s tools team.</p>
<p>The EAR trace generation mechanism was designed to support different trace generation plug-ins although the Paraver trace plug-in is the only supported by now. You must set the value of this variable to <code>tracer_paraver.so</code> to load the tracer. This shared object comes with the official EAR distribution and it is located at <code>$EAR_INSTALL_PATH/lib/plugins/tracer</code>. Then you need to set the <code>EAR_TRACE_PATH</code> variable (see below) to specify the destination path of the generated Paraver traces.</p>
<h2><a class="anchor" id="autotoc_md39"></a>
EAR_TRACE_PATH</h2>
<p>Specify the path where you want to store the trace files generated by the EAR Library. The path must be fully created. Otherwise, the Paraver tracer plug-in won’t be loaded.</p>
<p>Here is an example of the usage of the above explained environment variables:</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">export EAR_TRACE_PLUGIN=tracer_paraver.so</div>
<div class="line">export EAR_TRACE_PATH=$(pwd)/traces</div>
<div class="line">mkdir -p $EAR_TRACE_PATH</div>
<div class="line"> </div>
<div class="line">srun -n 10 --ear=on ./mpi_app</div>
</div><!-- fragment --><h2><a class="anchor" id="report_earl_events"></a>
REPORT_EARL_EVENTS</h2>
<p>Use this variable (i.e., <code>export REPORT_EARL_EVENTS=1</code>) to make EARL send internal events to the [Database](EAR-Database). These events are useful to have more information about Library's behaviour, like when DynAIS **(REFERENCE DYNAIS)** is turned off, the computational phase EAR is guessing the application is on or the status of the applied policy **(REF POLICIES)**. You can query job-specific events through <code>eacct -j &lt;JobID&gt; -x</code>, and you will get a table of all reported events:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Field name   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Event_ID   </td><td class="markdownTableBodyNone">Internal ID of the event stored at the Database.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Timestamp   </td><td class="markdownTableBodyNone"><em>yyyy-mm-dd hh:mm:ss</em>.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Event_type   </td><td class="markdownTableBodyNone">Which kind of event is it. Possible event types explained below.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Job_id   </td><td class="markdownTableBodyNone">The JobID of the event.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Value   </td><td class="markdownTableBodyNone">The value stored with the event. Categorical events explained below.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">node_id   </td><td class="markdownTableBodyNone">The node from where the event was reported.   </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md40"></a>
Event types</h3>
<p>Below are listed all kind of event types you can get when requesting job events. For categorical event values, the (value, category) mapping is explained.</p>
<ul>
<li><b>policy_error</b> Reported when the policy couldn't select the optimal frequency.</li>
<li><b>dynais_off</b> Reported when DynAIS is turned off and the Library becomes in <em>periodic monitoring mode</em>.</li>
<li><b>earl_state</b> The internal EARL state. Possible values are:<ul>
<li><b>0</b> This is the initial state and stands for no iteration detected.</li>
<li><b>1</b> EAR starts computing the signature</li>
<li><b>2</b> EAR computes the local signature and executes the per-node policy.</li>
<li><b>3</b> This state computes a new signature and evaluates the accuracy of the policy.</li>
<li><b>4</b> Projection error.</li>
<li><b>5</b> This is a transition state to recompute EARL timings just in case we need to adapt it because of the frequency selection.</li>
<li><b>6</b> Signature has changed.</li>
</ul>
</li>
<li><b>optim_accuracy</b> The internal optimization policy state. Possible values are:<ul>
<li><b>0</b> Policy not ready.</li>
<li><b>1</b> Policy says all is ok.</li>
<li><b>2</b> Policy says it'n not ok.</li>
<li><b>3</b> Policy wants to try again to optimize.</li>
</ul>
</li>
</ul>
<blockquote class="doxtable">
<p>&zwj;The above event types may be useful only for advanced users. Please, contact with <a href="#" onclick="location.href='mai'+'lto:'+'ear'+'-s'+'upp'+'or'+'t@b'+'sc'+'.es'; return false;">ear-support@bsc.es</a> if you want to know more about EARL internals. </p>
</blockquote>
<ul>
<li><b>energy_saving</b> Energy (in %) EAR is guessing the policy is saving.</li>
<li><b>power_saving</b> Power in (in %) EAR is guessing the policy is saving.</li>
<li><b>performance_penalty</b> Execution time (in %) EAR is guessing the policy is incrementing. </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6 </li>
  </ul>
</div>
</body>
</html>
